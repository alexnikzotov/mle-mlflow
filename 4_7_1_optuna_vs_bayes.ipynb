{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26943a72",
   "metadata": {},
   "source": [
    "<h1><center>OPTUNA vs БАЙЕС</center></h1>\n",
    "\n",
    "Вернёмся к анализу датасета «Космолайна» об оттоке клиентов. До этого вы применяли к нему методы Grid Search и Random Search для оптимизации гиперпараметров модели. Новая задача — использовать байесовский подход. Вы будете работать с алгоритмом TPE. \n",
    "\n",
    "Как и до этого, вам предстоит обучить новую версию модели — но в этот раз интегрировав процесс обучения с библиотекой optuna для оптимизации гиперпараметров. Так, вы не только автоматизируете поиск наилучших настроек для модели, но и сделаете его более точным и целенаправленным. \n",
    "\n",
    "Вы также потренируетесь проводить интеграцию с MLflow. Напомним, что это позволяет систематизировать и сохранять информацию обо всех экспериментах, проведённых в ходе подбора гиперпараметров. И к тому же поможет анализировать результаты.\n",
    "\n",
    "Не забудем и про воспроизводимость. Для этого вы сохраните всю информацию о процессе подбора гиперпараметров в локальную базу данных. В реальных проектах это будет отличной страховкой, ведь вы сможете в любой момент восстановить условия эксперимента, повторить его и проверить результаты.\n",
    "\n",
    "Так начнём же.\n",
    "\n",
    "---\n",
    "\n",
    "Импортируем библиотеки и настроим параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from catboost import CatBoostClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import ( OneHotEncoder, SplineTransformer, QuantileTransformer, StandardScaler,\n",
    "                                    RobustScaler, PolynomialFeatures, KBinsDiscretizer )\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from autofeat import AutoFeatRegressor, AutoFeatClassifier\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from optuna.samplers import CmaEsSampler\n",
    "from mlflow.utils.mlflow_tags import MLFLOW_PARENT_RUN_ID\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "TABLE_NAME = \"clean_users_churn\" # таблица с данными\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "# EXPERIMENT_NAME = \"model_bayesian_search\" # ваш код здесь\n",
    "# RUN_NAME = \"model_bayesian_search_run\"\n",
    "# REGISTRY_MODEL_NAME = 'model_bayesian_search' # ваш код здесь\n",
    "# MLFLOW_PARENT_RUN_ID = 1 #'model_bayesian_search'\n",
    "\n",
    "# STUDY_DB_NAME = \"sqlite:///local.study.db\"\n",
    "# STUDY_NAME = \"model_bayesian_search\"\n",
    "\n",
    "# experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\\\n",
    "#     if not mlflow.get_experiment_by_name(EXPERIMENT_NAME)\\\n",
    "#     else mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfcf6c",
   "metadata": {},
   "source": [
    "Загрузим таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90946157",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\"host\": 'rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net', #os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "                        \"port\": '6432', #os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "                        \"dbname\": 'playground_mle_20250529_05fed48463', #os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "                        \"user\": 'mle_20250529_05fed48463', #os.getenv(\"DB_DESTINATION_USER\"),\n",
    "                        \"password\": '0c567edd8ad8472e87d5c85cc4d664e4' } #os.getenv(\"DB_DESTINATION_PASSWORD\")}\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df['target'] = (df['end_date'].notna()).astype(int)\n",
    "df.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e6c1c",
   "metadata": {},
   "source": [
    "Подготовим данные для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df = df.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36889f4b",
   "metadata": {},
   "source": [
    "**Задание 1**\n",
    "\n",
    "После того как вы выделили категориальные колонки, закодируйте их для подачи в вашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение категориальных колонок, которые будут преобразованы\n",
    "cat_columns = [\"type\", \"payment_method\", \"internet_service\", \"gender\"]\n",
    "\n",
    "# создание объекта OneHotEncoder для преобразования категориальных переменных\n",
    "# auto - автоматическое определение категорий\n",
    "# ignore - игнорировать ошибки, если встречается неизвестная категория\n",
    "# max_categories - максимальное количество уникальных категорий\n",
    "# sparse_output - вывод в виде разреженной матрицы, если False, то в виде обычного массива\n",
    "# drop=\"first\" - удаляет первую категорию, чтобы избежать ловушки мультиколлинеарности\n",
    "encoder_oh = OneHotEncoder(categories='auto', handle_unknown='ignore', max_categories=10, sparse_output=False, drop='first') # ваш код здесь #\n",
    "\n",
    "# применение OneHotEncoder к данным. Преобразование категориальных данных в массив\n",
    "encoded_features = encoder_oh.fit_transform(df[cat_columns].to_numpy()) # ваш код здесь #\n",
    "\n",
    "# преобразование полученных признаков в DataFrame и установка названий колонок\n",
    "# get_feature_names_out() - получение имён признаков после преобразования\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_oh.get_feature_names_out(cat_columns)) # ваш код здесь #\n",
    "\n",
    "# конкатенация исходного DataFrame с новым DataFrame, содержащим закодированные категориальные признаки\n",
    "# axis=1 означает конкатенацию по колонкам\n",
    "obj_df = pd.concat([obj_df, encoded_df], axis=1)\n",
    "\n",
    "obj_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e57a5",
   "metadata": {},
   "source": [
    "Сейчас поработайте с числовыми признаками: monthly_charges и total_charges. Из них можно сгенерировать довольно много признаков для вашей модели. \n",
    "\n",
    "**Задание 2**\n",
    "\n",
    "Напишите код преобразования числовых признаков в списке num_columns, используя следующие энкодеры:\n",
    "- SplineTransformer,\n",
    "- QuantileTransformer,\n",
    "- RobustScaler,\n",
    "- PolynomialFeatures,\n",
    "- KBinsDiscretizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [\"monthly_charges\", \"total_charges\"]\n",
    "\n",
    "n_knots = 3\n",
    "degree_spline = 4\n",
    "n_quantiles=100\n",
    "degree = 3\n",
    "n_bins = 5\n",
    "encode = 'ordinal'\n",
    "strategy = 'uniform'\n",
    "subsample = None\n",
    "\n",
    "# num_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "num_df = df[num_columns].copy()\n",
    "\n",
    "# SplineTransformer\n",
    "encoder_spl = SplineTransformer(n_knots=n_knots, degree=degree_spline) # ваш код здесь #\n",
    "encoded_features = encoder_spl.fit_transform(df[num_columns].to_numpy()) # ваш код здесь #\n",
    "encoded_df = pd.DataFrame( encoded_features, columns=encoder_spl.get_feature_names_out(num_columns) )\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "# QuantileTransformer\n",
    "encoder_q = QuantileTransformer(n_quantiles=n_quantiles) #, output_distribution='normal') # ваш код здесь #\n",
    "encoded_features = encoder_q.fit_transform(df[num_columns].to_numpy()) # ваш код здесь #\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_q.get_feature_names_out(num_columns)) # ваш код здесь #\n",
    "encoded_df.columns = [col + f\"_q_{n_quantiles}\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "# RobustScaler\n",
    "encoder_rb = RobustScaler() # ваш код здесь #\n",
    "encoded_features = encoder_rb.fit_transform(df[num_columns].to_numpy()) # ваш код здесь #\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_rb.get_feature_names_out(num_columns)) # ваш код здесь #\n",
    "encoded_df.columns = [col + f\"_robust\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "# PolynomialFeatures\n",
    "encoder_pol = PolynomialFeatures(degree=degree) # ваш код здесь #\n",
    "encoded_features = encoder_pol.fit_transform(df[num_columns].to_numpy()) # ваш код здесь #\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_pol.get_feature_names_out(num_columns)) # ваш код здесь #\n",
    "# get all columns after the intercept and original features\n",
    "encoded_df.columns = encoder_pol.get_feature_names_out(num_columns)\n",
    "encoded_df = encoded_df.iloc[:, 1 + len(num_columns):]\n",
    "encoded_df.columns = [f\"{col}_poly\" for col in encoded_df.columns]\n",
    "\n",
    "# KBinsDiscretizer\n",
    "encoder_kbd = KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy, subsample=subsample) # ваш код здесь #\n",
    "encoded_features = encoder_kbd.fit_transform(df[num_columns].to_numpy()) # ваш код здесь #\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_kbd.get_feature_names_out(num_columns)) # ваш код здесь #\n",
    "encoded_df.columns = [col + f\"_bin\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1) # ваш код здесь #\n",
    "\n",
    "num_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d0a31",
   "metadata": {},
   "source": [
    "Трансформируем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = ColumnTransformer(transformers=[('spl', encoder_spl, num_columns),('q', encoder_q, num_columns), ('rb', encoder_rb, num_columns), ('pol', encoder_pol, num_columns), ('kbd', encoder_kbd, num_columns)])\n",
    "categorical_transformer = Pipeline(steps=[('encoder', encoder_oh)] )\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, num_columns), ('cat', categorical_transformer, cat_columns)], n_jobs=-1)\n",
    "encoded_features = preprocessor.fit_transform(df) # ваш код здесь #\n",
    "transformed_df = pd.DataFrame(encoded_features, columns=preprocessor.get_feature_names_out()) # ваш код здесь #\n",
    "\n",
    "df = pd.concat([df, transformed_df], axis=1) # ваш код здесь #\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef0188",
   "metadata": {},
   "source": [
    "Выберем закодированные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['target', 'num__spl__monthly_charges_sp_0',\n",
    "       'num__spl__monthly_charges_sp_1', 'num__spl__monthly_charges_sp_2',\n",
    "       'num__spl__monthly_charges_sp_3', 'num__spl__monthly_charges_sp_4',\n",
    "       'num__spl__monthly_charges_sp_5', 'num__spl__total_charges_sp_0',\n",
    "       'num__spl__total_charges_sp_1', 'num__spl__total_charges_sp_2',\n",
    "       'num__spl__total_charges_sp_3', 'num__spl__total_charges_sp_4',\n",
    "       'num__spl__total_charges_sp_5', 'num__q__monthly_charges',\n",
    "       'num__q__total_charges', 'num__rb__monthly_charges',\n",
    "       'num__rb__total_charges', 'num__pol__1', 'num__pol__monthly_charges',\n",
    "       'num__pol__total_charges', 'num__pol__monthly_charges^2',\n",
    "       'num__pol__monthly_charges total_charges', 'num__pol__total_charges^2',\n",
    "       'num__pol__monthly_charges^3',\n",
    "       'num__pol__monthly_charges^2 total_charges',\n",
    "       'num__pol__monthly_charges total_charges^2',\n",
    "       'num__pol__total_charges^3', 'num__kbd__monthly_charges',\n",
    "       'num__kbd__total_charges', 'cat__type_One year', 'cat__type_Two year',\n",
    "       'cat__payment_method_Credit card (automatic)',\n",
    "       'cat__payment_method_Electronic check',\n",
    "       'cat__payment_method_Mailed check', 'cat__internet_service_Fiber optic',\n",
    "       'cat__gender_Male']]\n",
    "\n",
    "# Разделение данных на обучающую и валидационную выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b25a737",
   "metadata": {},
   "source": [
    "Применим optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"YCAJE3Nlz8iDILW5VTYM1ihQB\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"YCPjvS7uwhvJpUj3bKm8X-IX4QAwBIVsvX61IL44\"\n",
    "os.environ['MLFLOW_ARTIFACT_URI'] = 'http://s3-student-mle-20250529-05fed48463'\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"model_bayesian_search\" # ваш код здесь\n",
    "RUN_NAME = \"model_bayesian_search\"\n",
    "# MLFLOW_PARENT_RUN_ID = \"model_bayesian_search_parent\"\n",
    "\n",
    "STUDY_DB_NAME = \"sqlite:///local.study.db\"\n",
    "STUDY_NAME = \"churn_model\"\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# def objective(trial: optuna.Trial) -> float:\n",
    "def objective(trial, X_train, y_train):\n",
    "    param = { \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "              \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "              \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.1, 5),\n",
    "              \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 5),\n",
    "              \"loss_function\": \"Logloss\",\n",
    "              \"task_type\": \"CPU\",\n",
    "              \"random_seed\": 0,\n",
    "              \"iterations\": 300,\n",
    "              \"verbose\": False } # ваш код здесь #\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "    skf = StratifiedKFold(n_splits=2) # ваш код здесь #)\n",
    "\n",
    "    metrics = defaultdict(list)\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        # ваш код здесь #\n",
    "        train_x = X_train.iloc[train_index]  # Добавление train_x\n",
    "        train_y = y_train.iloc[train_index]\n",
    "        val_x = X_train.iloc[val_index] # Добавление val_x \n",
    "        val_y = y_train.iloc[val_index]\n",
    "        # X_train_fold, X_val_fold = X_train[train_index], X_train[val_index] # Отключен по совету НС\n",
    "        # y_train_fold, y_val_fold = y_train[train_index], y_train[val_index] # Отклюсен по совету НС\n",
    "\n",
    "        X_train_fold, X_val_fold = train_x, val_x\n",
    "        y_train_fold, y_val_fold = train_y, val_y\n",
    "        \n",
    "        model.fit(train_x, train_y)  # Использование train_x для обучения модели\n",
    "        probas = model.predict_proba(val_x)[:, 1]\n",
    "        prediction = model.predict(val_x)\n",
    "\n",
    "        _, err1, _, err2 = confusion_matrix(val_y, prediction, normalize='all').ravel()\n",
    "        auc = roc_auc_score(val_y, probas)\n",
    "        precision = precision_score(val_y, prediction)\n",
    "        recall = recall_score(val_y, prediction)\n",
    "        f1 = f1_score(val_y, prediction)\n",
    "        logloss = log_loss(val_y, prediction)\n",
    "        \n",
    "        metrics[\"err1\"].append(err1)\n",
    "        metrics[\"err2\"].append(err2)\n",
    "        metrics[\"auc\"].append(auc)\n",
    "        metrics[\"precision\"].append(precision)\n",
    "        metrics[\"recall\"].append(recall)\n",
    "        metrics[\"f1\"].append(f1)\n",
    "        metrics[\"logloss\"].append(logloss)\n",
    "\n",
    "    # ваш код здесь #\n",
    "    err1 = sum(metrics[\"err1\"]) / len(metrics[\"err1\"])\n",
    "    err_1 = np.median(np.array(metrics['err1']))\n",
    "    err2 = sum(metrics[\"err2\"]) / len(metrics[\"err2\"])\n",
    "    err_2 = np.median(np.array(metrics['err2']))\n",
    "    auc = np.median(np.array(metrics['auc']))\n",
    "    precision = np.median(np.array(metrics['precision']))\n",
    "    recall = np.median(np.array(metrics['recall']))\n",
    "    f1 = np.median(np.array(metrics['f1']))\n",
    "    logloss = np.median(np.array(metrics['logloss']))\n",
    "\n",
    "    return auc\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if not experiment:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "#     run_id = run.info.run_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    best_model = CatBoostClassifier(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Сохраняем модель в MLFlow\n",
    "    mlflow.catboost.log_model(best_model, \"best_model\", artifact_path=\"cv\")\n",
    "    mlflow.log_params(best_params)  # записываем параметры модели\n",
    "    mlflow.log_metrics({\"auc\": auc, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"logloss\": logloss})\n",
    "\n",
    "mlflc = MLflowCallback(metric_name='AUC', tracking_uri=f'http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}',\n",
    "                       create_experiment=False,\n",
    "                       mlflow_kwargs={'experiment_id': experiment_id, 'tags':{MLFLOW_PARENT_RUN_ID:run_id}}) # ваш код здесь #\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name=STUDY_NAME, storage=STUDY_DB_NAME,\\\n",
    "                            sampler=optuna.samplers.TPESampler(), load_if_exists=True) # ваш код здесь #\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=10, callbacks=[mlflc])\n",
    "best_params = study.best_params # ваш код здесь #\n",
    "\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(f\"Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d347aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    model = CatBoostClassifier(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    mlflow.catboost.log_model(model, \"best_model\")  # сохраняем модель в MLFlow\n",
    "    # mlflow.log_params(param)  # записываем параметры модели\n",
    "    mlflow.log_metrics({\"auc\": auc, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"logloss\": logloss})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
