{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26943a72",
   "metadata": {},
   "source": [
    "<h1><center>OPTUNA vs БАЙЕС</center></h1>\n",
    "\n",
    "Вернёмся к анализу датасета «Космолайна» об оттоке клиентов. До этого вы применяли к нему методы Grid Search и Random Search для оптимизации гиперпараметров модели. Новая задача — использовать байесовский подход. Вы будете работать с алгоритмом TPE. \n",
    "\n",
    "Как и до этого, вам предстоит обучить новую версию модели — но в этот раз интегрировав процесс обучения с библиотекой optuna для оптимизации гиперпараметров. Так, вы не только автоматизируете поиск наилучших настроек для модели, но и сделаете его более точным и целенаправленным. \n",
    "\n",
    "Вы также потренируетесь проводить интеграцию с MLflow. Напомним, что это позволяет систематизировать и сохранять информацию обо всех экспериментах, проведённых в ходе подбора гиперпараметров. И к тому же поможет анализировать результаты.\n",
    "\n",
    "Не забудем и про воспроизводимость. Для этого вы сохраните всю информацию о процессе подбора гиперпараметров в локальную базу данных. В реальных проектах это будет отличной страховкой, ведь вы сможете в любой момент восстановить условия эксперимента, повторить его и проверить результаты.\n",
    "\n",
    "Так начнём же.\n",
    "\n",
    "---\n",
    "\n",
    "Импортируем библиотеки и настроим параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from catboost import CatBoostClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import ( OneHotEncoder, SplineTransformer, QuantileTransformer, StandardScaler,\n",
    "                                    RobustScaler, PolynomialFeatures, KBinsDiscretizer )\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from autofeat import AutoFeatRegressor, AutoFeatClassifier\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "TABLE_NAME = \"clean_users_churn\" # таблица с данными\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = \"model_bayesian_search\" # ваш код здесь\n",
    "RUN_NAME = \"model_bayesian_search\"\n",
    "REGISTRY_MODEL_NAME = 'model_bayesian_search' # ваш код здесь\n",
    "\n",
    "STUDY_DB_NAME = \"sqlite:///local.study.db\"\n",
    "STUDY_NAME = \"churn_model\"\n",
    "\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\\\n",
    "    if not mlflow.get_experiment_by_name(EXPERIMENT_NAME)\\\n",
    "    else mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d296f",
   "metadata": {},
   "source": [
    "Загрузим таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63131faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\"host\": 'rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net', #os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "                        \"port\": '6432', #os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "                        \"dbname\": 'playground_mle_20250529_05fed48463', #os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "                        \"user\": 'mle_20250529_05fed48463', #os.getenv(\"DB_DESTINATION_USER\"),\n",
    "                        \"password\": '0c567edd8ad8472e87d5c85cc4d664e4' } #os.getenv(\"DB_DESTINATION_PASSWORD\")}\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df['target'] = (df['end_date'].notna()).astype(int)\n",
    "df.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e878562",
   "metadata": {},
   "source": [
    "Подготовим данные для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим признаки в три отдельные таблицы для дальнейшей работы:\n",
    "features = df.drop(['customer_id','target'],axis=1)\n",
    "num_features = features.select_dtypes(include=['float', 'int'])\n",
    "date_features = features.select_dtypes(include='datetime64[ns]')\n",
    "cat_features = features.select_dtypes(include='object')\n",
    "\n",
    "# Посчитаем колво уникальных значений для катег. переменных и создадим создадим два датасета:\n",
    "unique_values_per_col = cat_features.nunique().value_counts()\n",
    "binary_cat_features = cat_features[ [i for i in cat_features.columns if cat_features[i].nunique()==2] ]\n",
    "other_cat_features = cat_features[ [i for i in cat_features.columns if cat_features[i].nunique()!=2] ]\n",
    "\n",
    "# Бинарные подразделяем на два - \"да/нет\" и другие бинарные:\n",
    "yes_no_features = binary_cat_features[ [i for i in binary_cat_features.columns if\\\n",
    "binary_cat_features[i].isin(['Yes','yes','No','no',None,np.nan]).all()==True] ]\n",
    "other_binary_features = binary_cat_features[ [i for i in binary_cat_features.columns if\\\n",
    "binary_cat_features[i].isin(['Yes','yes','No','no',None,np.nan]).all()!=True] ]\n",
    "\n",
    "# Дубликаты\n",
    "is_duplicated_id = df.duplicated(subset=['customer_id'], keep=False)\n",
    "\n",
    "# Пропуски\n",
    "cols_with_nans = df.isnull().sum()\n",
    "cols_with_nans = cols_with_nans[cols_with_nans > 0].index.drop('end_date')\n",
    "for col in cols_with_nans:\n",
    "    if df[col].dtype in [float, int]:\n",
    "        fill_value = df[col].mean()\n",
    "    elif df[col].dtype == 'object':\n",
    "        fill_value = df[col].mode().iloc[0]\n",
    "    df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "# Выбросы\n",
    "num_cols = df.select_dtypes(['float']).columns\n",
    "threshold = 1.5\n",
    "potential_outliers = pd.DataFrame()\n",
    "for col in num_cols:\n",
    "\tQ1 = df[col].quantile(0.25)\n",
    "\tQ3 = df[col].quantile(0.75)\n",
    "\tIQR = Q3 - Q1\n",
    "\tmargin = threshold * IQR\n",
    "\tlower = Q1 - margin\n",
    "\tupper = Q3 + margin\n",
    "\tpotential_outliers[col] = ~df[col].between(lower, upper)\n",
    "outliers = potential_outliers.any(axis=1)\n",
    "\n",
    "df.drop(columns=['id', 'customer_id', 'begin_date', 'end_date'], inplace=True)\n",
    "df[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedc39c",
   "metadata": {},
   "source": [
    "Первично обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"monthly_charges\", \"total_charges\", \"senior_citizen\"]\n",
    "target = \"target\"\n",
    "\n",
    "split_column = \"monthly_charges\" # ваш код здесь\n",
    "stratify_column = target # ваш код здесь\n",
    "test_size = 0.2 # ваш код здесь\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target],\\\n",
    "                                   test_size=test_size, shuffle=False) # ваш код здесь\n",
    "\n",
    "print(f\"Размер выборки для обучения: {X_train.shape}\")\n",
    "print(f\"Размер выборки для теста: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f6e79",
   "metadata": {},
   "source": [
    "И теперь применим optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    param = { \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "              \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "              \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.1, 5),\n",
    "              \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 5),\n",
    "              \"loss_function\": \"Logloss\",\n",
    "              \"task_type\": \"CPU\",\n",
    "              \"random_seed\": 0,\n",
    "              \"iterations\": 300,\n",
    "              \"verbose\": False } # ваш код здесь #\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=2) # ваш код здесь #)\n",
    "\n",
    "    metrics = defaultdict(list)\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        # ваш код здесь #\n",
    "        train_x = X_train.iloc[train_index]  # Добавление train_x\n",
    "        train_y = y_train.iloc[train_index]\n",
    "        val_x = X_train.iloc[val_index] # Добавление val_x \n",
    "        val_y = y_train.iloc[val_index]\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model.fit(train_x, train_y)  # Использование train_x для обучения модели\n",
    "        probas = model.predict_proba(val_x)[:, 1]\n",
    "        prediction = model.predict(val_x)\n",
    "\n",
    "        _, err1, _, err2 = confusion_matrix(val_y, prediction, normalize='all').ravel()\n",
    "        auc = roc_auc_score(val_y, probas)\n",
    "        precision = precision_score(val_y, prediction)\n",
    "        recall = recall_score(val_y, prediction)\n",
    "        f1 = f1_score(val_y, prediction)\n",
    "        logloss = log_loss(val_y, prediction)\n",
    "        \n",
    "        metrics[\"err1\"].append(err1)\n",
    "        metrics[\"err2\"].append(err2)\n",
    "        metrics[\"auc\"].append(auc)\n",
    "        metrics[\"precision\"].append(precision)\n",
    "        metrics[\"recall\"].append(recall)\n",
    "        metrics[\"f1\"].append(f1)\n",
    "        metrics[\"logloss\"].append(logloss)\n",
    "\n",
    "\n",
    "    # ваш код здесь #\n",
    "    err1 = sum(metrics[\"err1\"]) / len(metrics[\"err1\"])\n",
    "    err_1 = median(array(metrics['err1']))\n",
    "    err2 = sum(metrics[\"err2\"]) / len(metrics[\"err2\"])\n",
    "    err_2 = median(array(metrics['err2']))\n",
    "    auc = median(array(metrics['auc']))\n",
    "    precision = median(array(metrics['precision']))\n",
    "    recall = median(array(metrics['recall']))\n",
    "    f1 = median(array(metrics['f1']))\n",
    "    logloss = median(array(metrics['logloss']))\n",
    "\n",
    "    return auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a5390",
   "metadata": {},
   "source": [
    "Залогируем всё это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = 'YCAJE3Nlz8iDILW5VTYM1ihQB' #os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = 'YCPjvS7uwhvJpUj3bKm8X-IX4QAwBIVsvX61IL44' #os.getenv(\"S3_SECRET_KEY\")\n",
    "os.environ['MLFLOW_ARTIFACT_URI'] = 'http://s3-student-mle-20250529-05fed48463'\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if not experiment:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflc = MlflowCallback(tracking_uri=f'http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}',\n",
    "metric_name='AUC', create_experiment=False, experiment_name=EXPERIMENT_NAME,\n",
    "mlflow_kwargs={'experiment_id': experiment_id, 'tags': {MLFLOW_PARENT_RUN_ID: run_id}}) # ваш код здесь #\n",
    "\n",
    "study = optuna.create_study(study_name=STUDY_NAME, storage=STUDY_DB_NAME,\n",
    "sampler=optuna.samplers.TPESampler(), direction='maximize') # ваш код здесь #\n",
    "study.optimize(objective, n_trials=10, callbacks=[mlflc]) # ваш код здесь #)\n",
    "best_params = study.best_params # ваш код здесь #\n",
    "\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(f\"Best params: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
