{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0997dc37",
   "metadata": {},
   "source": [
    "<h1><center>ЛОГИРОВАНИЕ В MLFLOW НА ПРАКТИКЕ</h1></center>\n",
    "\n",
    "MLflow Tracking Server запущен (с помощью команды sh run_mlflow_server.sh) — можно начинать что-то туда логировать.<br>Перед этим стоит достать ваш датафрейм из базы данных Postgres. Сделать это можно при помощи кода, рассмотренного ранее: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = { \"host\": \"rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net\", \n",
    "                         \"port\": \"6432\",\n",
    "                         \"dbname\": \"playground_mle_20250529_05fed48463\",\n",
    "                         \"user\": \"mle_20250529_05fed48463\",\n",
    "                         \"password\": \"0c567edd8ad8472e87d5c85cc4d664e4\" }\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определим название таблицы, в которой хранятся наши данные.\n",
    "TABLE_NAME = \"clean_users_churn\"\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n",
    "# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаёт объект курсора для выполнения запросов к базе данных\n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # получает список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаёт объект DataFrame из полученных данных и имён столбцов. \n",
    "# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\n",
    "df = pd.DataFrame(data, columns=columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880be1b",
   "metadata": {},
   "source": [
    "Ваша цель - создать текстовый файл с названием columns_sol.txt и сохранить в него названия колонок датафрейма, используя , как разделитель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa1537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список названий колонок из датафрейма df\n",
    "columns = df.columns\n",
    "\n",
    "# 1. Название колонок вашего датафрейма запишите в текстовый файл\n",
    "with open(\"columns_sol.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "    fio.write(\",\".join(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a1742",
   "metadata": {},
   "source": [
    "Посчитайте различные статистики (минимальные, максимальные, средние и медианы) по вашему датафрейму для определённых колонок (count_columns) и запишите результат в Python-словарь. Для подсчёта воспользуйтесь функцией value_counts. Это нужно, чтобы понимать, на каких данных была обучена ваша модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_columns = [\"type\", \"paperless_billing\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "    \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\",\n",
    "    \"multiple_lines\", \"target\"]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for col in counts_columns:\n",
    "    # посчитайте уникальные значения для колонок, где немного уникальных значений (переменная counts_columns)\n",
    "    column_stat = df[col].value_counts().to_dict()\n",
    "    column_stat = {f\"{col}_{key}\": value for key, value in column_stat.items()}\n",
    "\n",
    "    # обновите словарь stats\n",
    "    stats.update(column_stat)\n",
    "\n",
    "stats[\"data_length\"] = df.shape[0]\n",
    "stats[\"monthly_charges_min\"] = df[\"monthly_charges\"].min()\n",
    "stats[\"monthly_charges_max\"] = df[\"monthly_charges\"].max() # посчитайте максимальное значение в колонке\n",
    "stats[\"monthly_charges_mean\"] = df[\"monthly_charges\"].mean() # посчитайте среднее значение в колонке\n",
    "stats[\"monthly_charges_median\"] = df[\"monthly_charges\"].median() # посчитайте медианное значение в колонке\n",
    "stats[\"total_charges_min\"] = df[\"total_charges\"].min() # посчитайте минимальное значение в колонке\n",
    "stats[\"total_charges_max\"] = df[\"total_charges\"].max() # посчитайте максимальное значение в колонке\n",
    "stats[\"total_charges_mean\"] = df[\"total_charges\"].mean() # посчитайте среднее значение в колонке\n",
    "stats[\"total_charges_median\"] = df[\"total_charges\"].median() # посчитайте медианное значение в колонке\n",
    "stats[\"unique_customers_number\"] = df[\"customer_id\"].nunique() # посчитайте кол-во уникальных id\n",
    "stats[\"end_date_nan\"] = df[\"end_date\"].isna().sum() # посчитайте кол-во пустых строк в колонке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d629e",
   "metadata": {},
   "source": [
    "Если в проекте есть такая возможность, а размер вашего датасета не превышает несколько гигабайт, то можно сохранить и сам датафрейм. Например, в формате CSV: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0e1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('users_churn.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f378d9",
   "metadata": {},
   "source": [
    "Ваша задача:\n",
    "- Залогируйте ваши первые артефакты, создав новый эксперимент. В качестве директории для артефактов используйте dataframe.\n",
    "- Проверьте, что ваш запуск прошёл успешно.\n",
    "- Удалите файл с колонками и сам датафрейм, чтобы они не занимали место на диске на локальной машине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5320bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаём название эксперимента и имя запуска для логирования в MLflow\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_fio_2\"\n",
    "RUN_NAME = \"data_check_2\"\n",
    "\n",
    "# создаём новый эксперимент в MLflow с указанным названием \n",
    "# если эксперимент с таким именем уже существует, \n",
    "# MLflow возвращает идентификатор существующего эксперимента\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) if not mlflow.get_experiment_by_name(EXPERIMENT_NAME) else mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    mlflow.set_tag(\"mlflow.runName\", RUN_NAME) \n",
    "\n",
    "    # получаем уникальный идентификатор запуска эксперимента\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # логируем метрики эксперимента\n",
    "    # предполагается, что переменная stats содержит словарь с метриками,\n",
    "    # объявлять переменную stats не надо,\n",
    "    # где ключи — это названия метрик, а значения — числовые значения метрик\n",
    "    mlflow.log_metrics(stats)\n",
    "    \n",
    "    # логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\n",
    "    mlflow.log_artifact(\"columns_sol.txt\",'dataframe')\n",
    "    mlflow.log_artifact(\"users_churn.csv\",'dataframe') \n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# получаем данные о запуске эксперимента по его уникальному идентификатору\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "\n",
    "# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\n",
    "# это утверждение (assert) можно использовать для автоматической проверки того, \n",
    "# что эксперимент был завершён успешно\n",
    "assert run.info.status == \"FINISHED\"\n",
    "\n",
    "# удаляем файлы 'columns.txt' и 'users_churn.csv' из файловой системы,\n",
    "# чтобы очистить рабочую среду после логирования артефактов\n",
    "os.remove('columns_sol.txt')\n",
    "os.remove('users_churn.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
